{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/STRMNGnwo/CT5133-DeepLearning/blob/main/DeepLearningAssignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CT5133 - Assignment 1\n",
        "\n",
        "  -Submitted by Srinivas Ilancheran (19280039) and Lukasz Szemet (19502109) of the MSc Artificial Intelligence programme\n",
        "\n"
      ],
      "metadata": {
        "id": "8kPCghdty9Sv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment Sections:"
      ],
      "metadata": {
        "id": "0FJ88ToL0g6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 1"
      ],
      "metadata": {
        "id": "HztzM9Oj02Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instructions:**\n",
        "\n",
        "Implement Logistic Regression (Topic 2):\n",
        "  1. Use Jupyter Notebook (Python or R) to implement a neural network approach to logistic regression (no hidden layers, one output node)\n",
        "  2. Your code should follow my notes to implement the algorithm from scratch.\n",
        "  3. Your notebook should include a brief description of the algorithm, with all references.\n",
        "  4. Your code must handle different numbers of inputs and different numbers of training cases, but you don't have to support more than one binary output node"
      ],
      "metadata": {
        "id": "1lL8cTmG1DH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1 notes\n",
        "\n",
        "Class node\n",
        "4 functions\n",
        "contructor(input then init weights), activation(sigmoid function), weighted sum(w .  x + b), forward\n"
      ],
      "metadata": {
        "id": "LDUkdOnxdI7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "UT8Xtr5QiG2A"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegressionNeuron:\n",
        "\n",
        "  def __init__(self,initial_weight):\n",
        "\n",
        "\n",
        "    self.weights=initial_weight\n",
        "\n",
        "    # initialising a bias value\n",
        "    self.bias=np.random.rand((1,1))\n",
        "\n",
        "\n",
        "  def weighted_sum_func(self,input):\n",
        "\n",
        "    return np.dot(np.array(input),self.weights) + self.bias\n",
        "\n",
        "\n",
        "  def activation_func(self,input):\n",
        "\n",
        "      return 1/(1+np.exp(-input))\n",
        "\n",
        "\n",
        "  def forward(self,input):\n",
        "\n",
        "    #defining a single pass\n",
        "\n",
        "    #send the input into the weighted sum function, to get W . input\n",
        "\n",
        "    weighted_sum=self.weighted_sum_func(input)\n",
        "\n",
        "    #send the weighted_sum into the activation function (sigmoid) to get either a 0, or a 1 (based on threshold value)\n",
        "    activation_output=self.activation_func(weighted_sum)\n",
        "\n",
        "    return activation_output\n",
        "\n"
      ],
      "metadata": {
        "id": "JQTSPzI6zNwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get random sample\n",
        "initial_sample=\n",
        "\n",
        "# creating a weights matrix that is the same shape as an input sample\n",
        "initial_weight=np.random.rand(initial_sample.shape)\n",
        "\n",
        "#initialising the LogisiticRegression Neuron\n",
        "LR_Model=LogisticRegressionNeuron(initial_weight)\n",
        "\n",
        "#array to store samples\n",
        "samples= []\n",
        "\n",
        "# time (iteration) values\n",
        "epochs=5\n",
        "max_iterations= len(samples)*epochs\n",
        "learning_rate=0.0001\n",
        "\n",
        "#probability threshold:\n",
        "threshold=0.5\n",
        "\n",
        "i=0\n",
        "\n",
        "prev_loss=0\n",
        "running_loss=0\n",
        "#Training loop to perform SGD:\n",
        "while i<max_iterations:\n",
        "  #randomly choose a training sample from samples\n",
        "  input_sample=np.array(samples[np.random.randint(len(samples))])\n",
        "\n",
        "  #model output -> probability\n",
        "  probability=LR_Model.forward(input_sample)\n",
        "\n",
        "  #convert probability into label\n",
        "  predicted_label=1 if probability>0.5 else 0\n",
        "\n",
        "  #calculate loss using Stochastic Gradient Descent\n",
        "  # input_sample[1] is true class value\n",
        "  curr_loss = -((input_sample[1]*np.log(probability)) + (1-input_sample[1]) * np.log(1-probability))\n",
        "\n",
        "  delta_w = np.zeros(LR_Model.weights.shape)\n",
        "\n",
        "  for idx, weight in enumerate(LR_Model.weights):\n",
        "    delta_w[idx] = (probability - input_sample[1])*input_sample[0][idx]\n",
        "\n",
        "  delta_b = (probability - input_sample[1])\n",
        "\n",
        "  for idx, weight in enumerate(LR_Model.weights):\n",
        "    LR_Model.weights[idx] -= learning_rate * delta_w[idx]\n",
        "\n",
        "  LR_Model.bias -= learning_rate * delta_b\n",
        "\n",
        "  i += 1\n",
        "  running_loss += curr_loss\n",
        "\n",
        "  if i%len(samples)==0:\n",
        "    if (running_loss-prev_loss) < 10**(-4): #latter condition is to check for convergence (change in weights is minimal)\n",
        "      i = max_iterations\n",
        "    prev_loss = running_loss\n",
        "    running_loss = 0\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d6f7u3EvmToR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2"
      ],
      "metadata": {
        "id": "Lwatvyh504vw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instructions:**\n",
        "\n",
        "• I will supply two fairly small datasets:\n",
        "  – One will be linearly separable (almost or fully), the other will not\n",
        "  – I will provide sample Python code to load and plot the datasets; you are\n",
        "allowed to use this code in your own assignment\n",
        "\n",
        "• Divide each dataset randomly into:\n",
        "  – Training set (70%):use for main training\n",
        "  – Validation set (15%): use for tuning, e.g. selecting learning rates\n",
        "  – Test set (15%): held out set for final performance evaluation\n",
        "\n",
        "• Train a logistic regressor using your code from\n",
        "Part 1, and see how it performs on both datasets\n",
        "\n",
        "• In your notebook, summarise results and\n",
        "provide observations and conclusions\n"
      ],
      "metadata": {
        "id": "RaBW9cDV1wJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using pandas to read in the csv"
      ],
      "metadata": {
        "id": "P3Nba_KXoEm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 3"
      ],
      "metadata": {
        "id": "4z5Yawwu07Q-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 4"
      ],
      "metadata": {
        "id": "VFGBp94H08gK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 5"
      ],
      "metadata": {
        "id": "v7BQDYcC09tZ"
      }
    }
  ]
}